# -*- coding: utf-8 -*-
"""UL19_Training.ipynb
Automatically generated by Colaboratory.
Original file is located at
    https://colab.research.google.com/drive/1xHc5qLSXBN-vo_rlltkKJ7Z1N3SR7_2Z
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import cv2
import keras
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import random

from keras.models import Model
from keras.layers import Dropout, Dense, BatchNormalization
from keras.callbacks import ModelCheckpoint
from keras.applications.mobilenet_v2 import MobileNetV2
from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img

plt.style.use('ggplot')

# %matplotlib inline

# COLAB-ONLY: load/save content from drive



"""# 1. Dataset
---
* Download, unzip and load
"""
# ------------------------------------------------------------------------------
# -- unzipping and storing to 'celeba-folder'
# ------------------------------------------------------------------------------
'''
import zipfile


def extract(path, folder):
    zip_ref = zipfile.ZipFile(path, 'r')
    zip_ref.extractall(folder)
    zip_ref.close()


base_folder = 'celeba-dataset'
extract(base_folder + ".zip", base_folder)

for file in os.listdir(base_folder):
    name, ext = os.path.splitext(file)
    if ext == ".zip":
        extract(os.path.join(base_folder, file), base_folder)

'''
# ------------------------------------------------------------------------------
# -- CelebA Class:
# ------------------------------------------------------------------------------

class CelebA():
    '''Wraps the celebA dataset, allowing an easy way to:
         - Select the features of interest,
         - Split the dataset into 'training', 'test' or 'validation' partition.
    '''

    def __init__(self, main_folder='../../celeba-dataset/', selected_features=None, drop_features=[]):
        self.main_folder = main_folder
        self.images_folder = os.path.join(main_folder, 'img_align_celeba/')
        self.attributes_path = os.path.join(main_folder, 'list_attr_celeba.csv')
        self.partition_path = os.path.join(main_folder, 'list_eval_partition.csv')
        self.selected_features = selected_features
        self.features_name = []
        self.__prepare(drop_features)

    def __prepare(self, drop_features):
        '''do some preprocessing before using the data: e.g. feature selection'''
        # attributes:
        if self.selected_features is None:
            self.attributes = pd.read_csv(self.attributes_path)
            self.num_features = 40
        else:
            self.num_features = len(self.selected_features)
            self.selected_features = self.selected_features.copy()
            self.selected_features.append('image_id')
            self.attributes = pd.read_csv(self.attributes_path)[self.selected_features]

        # remove unwanted features:
        for feature in drop_features:
            if feature in self.attributes:
                self.attributes = self.attributes.drop(feature, axis=1)
                self.num_features -= 1

        self.attributes.set_index('image_id', inplace=True)
        self.attributes.replace(to_replace=-1, value=0, inplace=True)
        self.attributes['image_id'] = list(self.attributes.index)

        self.features_name = list(self.attributes.columns)[:-1]

        # load ideal partitioning:
        self.partition = pd.read_csv(self.partition_path)
        self.partition.set_index('image_id', inplace=True)

    def split(self, name='training', drop_zero=False):
        '''Returns the ['training', 'validation', 'test'] split of the dataset'''
        # select partition split:
        if name is 'training':
            to_drop = self.partition.where(lambda x: x != 0).dropna()
        elif name is 'validation':
            to_drop = self.partition.where(lambda x: x != 1).dropna()
        elif name is 'test':  # test
            to_drop = self.partition.where(lambda x: x != 2).dropna()
        else:
            raise ValueError('CelebA.split() => `name` must be one of [training, validation, test]')

        partition = self.partition.drop(index=to_drop.index)

        # join attributes with selected partition:
        joint = partition.join(self.attributes, how='inner').drop('partition', axis=1)

        if drop_zero is True:
            # select rows with all zeros values
            return joint.loc[(joint[self.features_name] == 1).any(axis=1)]
        elif 0 <= drop_zero <= 1:
            zero = joint.loc[(joint[self.features_name] == 0).all(axis=1)]
            zero = zero.sample(frac=drop_zero)
            return joint.drop(index=zero.index)

        return joint


# loading dataset:

# discards the given attributes
# celeba = CelebA(drop_features=[
#     'Attractive',
#     'Pale_Skin',
#     'Blurry',
# ])

# loads all attributes (40)
celeba = CelebA()

"""# 2. Model Architecture
---
* MobileNetV2: as the base architecture pre-trained on 'imagenet'
* Summary: layers, num of parameters.
"""

# @title Model Input
img_size = 224  # @param ["192", "224"] {type:"raw", allow-input: true}

IMG_W = img_size
IMG_H = img_size
IMG_SHAPE = (IMG_H, IMG_W, 3)
TARGET_SIZE = (IMG_H, IMG_W)


# the architecture:

def mobilenet_model(num_features):
    base = MobileNetV2(input_shape=IMG_SHAPE,
                       weights=None,
                       include_top=False,
                       pooling='avg')

    # model top
    x = base.output
    x = Dense(1536, activation='relu')(x)
    x = BatchNormalization()(x)
    x = Dropout(0.3)(x)
    top = Dense(num_features, activation='sigmoid')(x)

    return Model(inputs=base.input, outputs=top)


model = mobilenet_model(num_features=celeba.num_features)

import os
os.environ["PATH"] += os.pathsep + "d:\\Program Files (x86)\\Graphviz2.38\\bin"

keras.utils.plot_model(
    model, to_file='modelkeras.png', show_shapes=True, show_layer_names=True,
    rankdir='TB', expand_nested=True, dpi=256
)
model.summary()

"""# 3. Training
---
* Data generators (for training and validation)
* Image Augmentation: zoom, rotation, shear, shift.
* Optimizer
* Checkpointing
* Fitting
"""

# @title Training Parameters
batch_size = 32  # @param ["64", "80", "96", "128"] {type:"raw", allow-input: true}
num_epochs = 12  # @param ["8", "16", "32"] {type:"raw", allow-input: true}

# ------------------------------------------------------------------------------
# -- Preparing Data Generators for training and validation set
# ------------------------------------------------------------------------------

# data augmentation only for the training istances:
train_datagen = ImageDataGenerator(rotation_range=20,
                                   rescale=1. / 255,
                                   width_shift_range=0.2,
                                   height_shift_range=0.2,
                                   shear_range=0.2,
                                   zoom_range=0.2,
                                   horizontal_flip=True,
                                   fill_mode='nearest')

valid_datagen = ImageDataGenerator(rescale=1. / 255)

# get training and validation set:
train_split = celeba.split('training', drop_zero=False)
valid_split = celeba.split('validation', drop_zero=False)

# data generators:
train_generator = train_datagen.flow_from_dataframe(
    dataframe=train_split,
    directory=celeba.images_folder,
    x_col='image_id',
    y_col=celeba.features_name,
    target_size=TARGET_SIZE,
    batch_size=batch_size,
    #class_mode='other'
    class_mode='raw'
)

valid_generator = valid_datagen.flow_from_dataframe(
    dataframe=valid_split,
    directory=celeba.images_folder,
    x_col='image_id',
    y_col=celeba.features_name,
    target_size=TARGET_SIZE,
    batch_size=batch_size,
    #class_mode='other'
    class_mode='raw'
)


# ------------------------------------------------------------------------------
# -- Example of the augmented samples:
# ------------------------------------------------------------------------------

def load_reshape_img(path, shape=IMG_SHAPE):
    img = load_img(path, target_size=shape)
    x = img_to_array(img) / 255.0
    x = x.reshape((1,) + x.shape)
    return x


# select and load a picture:
sample_path = os.path.join(celeba.images_folder, train_split.sample(1).index[0])
sample = load_reshape_img(sample_path)

# plot ten augmented images
plt.figure(figsize=(20, 10))
plt.suptitle('Data Augmentation Example', fontsize=28)

for i, image in enumerate(train_datagen.flow(sample, batch_size=1)):
    if i == 10:
        break

    plt.subplot(2, 5, i + 1)
    plt.grid(False)
    plt.imshow(image.reshape(IMG_SHAPE) * 255.)

_ = plt.show()

# ------------------------------------------------------------------------------
# -- Compile model
# ------------------------------------------------------------------------------

model.compile(loss='cosine_proximity',
              optimizer='adadelta',  # adadelta, adam, nadam
              metrics=['binary_accuracy'])

# ------------------------------------------------------------------------------
# -- Checkpointing: at each epoch, the best model so far is saved
# ------------------------------------------------------------------------------

save_path = 'd://Projects//Python//PycharmProjects//DLIB_Pytorch//checkpoints//'
# model_path = f"{save_path}/UL19/weights-FC37-MobileNetV2-" + "{val_binary_accuracy:.2f}.hdf5"
model_path = f"{save_path}/UL19_keras_01/weights-FC40-MobileNetV2" + "{val_binary_accuracy:.2f}.hdf5"

checkpoint = ModelCheckpoint(
    model_path,
    monitor='val_binary_accuracy',
    save_best_only=True,
    mode='max',
    verbose=1
)

# ------------------------------------------------------------------------------
# -- Fitting
# ----------------------------------------------------------------------------
if False:

    history = model.fit_generator(
        train_generator,
        epochs=num_epochs,
        steps_per_epoch=len(train_generator),
        validation_data=valid_generator,
        validation_steps=len(valid_generator),
        max_queue_size=1,
        shuffle=True,
        callbacks=[checkpoint],
        verbose=1
    )


    def plot_model_history(history):
        '''plots useful graphs about the model training: loss, accuracy, ecc.'''
        plt.plot(history.history['binary_accuracy'])
        plt.plot(history.history['val_binary_accuracy'])
        plt.title('Model accuracy')
        plt.ylabel('Accuracy')
        plt.xlabel('Epoch')
        plt.legend(['Train', 'Validation'], loc='upper left')
        plt.show()

        # Plot training & validation loss values
        plt.plot(history.history['loss'])
        plt.plot(history.history['val_loss'])
        plt.title('Model loss')
        plt.ylabel('Loss')
        plt.xlabel('Epoch')
        plt.legend(['Train', 'Validation'], loc='upper left')
        plt.show()


    # plot the training and validation loss for every epoch:
    plot_model_history(history)

"""# 4. Testing
---
* Test Data Generator
* Evaluate performance on test-set
* Average Hamming Distance, Mis-predictions
* Plot Mis-predictions frequency, and accuracy per feature
"""

# optionally load a pre-trained model:

model = keras.models.load_model(f"{save_path}/UL19_keras_01/weights-FC40-MobileNetV20.91.hdf5")
img = cv2.imread('d:\\Projects\\Python\\PycharmProjects\\celeba-dataset\\img_align_celeba\\000007.jpg')
img = cv2.resize(img, (224,224)) / 255
img = np.expand_dims(img, axis=0)
vv = model.predict(img)
res = ("X5_o_Clock_Shadow", "Arched_Eyebrows", "Attractive", "Bags_Under_Eyes","Bald", "Bangs",
         "Big_Lips", "Big_Nose", "Black_Hair", "Blond_Hair", "Blurry", "Brown_Hair", "Bushy_Eyebrows",
         "Chubby", "Double_Chin", "Eyeglasses", "Goatee", "Gray_Hair", "Heavy_Makeup",
         "High_Cheekbones", "Male", "Mouth_Slightly_Open", "Mustache", "Narrow_Eyes", "No_Beard",
         "Oval_Face","Pale_Skin","Pointy_Nose", "Receding_Hairline",    "Rosy_Cheeks", "Sideburns",
         "Smiling", "Straight_Hair", "Wavy_Hair", "Wearing_Earrings", "Wearing_Hat", "Wearing_Lipstick",
         "Wearing_Necklace", "Wearing_Necktie","Young")
for a in range(40):
    print(str(res[a]) + " " + str(vv[0,a]))